### 📌 한줄 정리

캐시 메모리는 CPU와 메인 메모리 속도 차이(폰 노이만 병목)를 줄이기 위해, 자주 쓰는 데이터와 명령어를 CPU 가까이에 저장하는 고속 메모리이다.

### 특징

- 휘발성이며 **SRAM(Static RAM) 기반**이다. 이는 DRAM보다 빠르지만 비싸고 용량이 작다.
- CPU와 메모리 사이의 병목을 완화한다.
- **참조 지역성(Locality) 원리**에 따라 성능이 향상된다.
    - **시간 지역성**: 최근 접근한 데이터는 곧 다시 접근될 가능성이 높다는 원리이다. `for` 문이 대표적인 예시로, 변수 `i`는 계속 사용된다.Python
        
        # 
        
        `sum = 0
        for i in range(10):
            sum += i`
        
    - **공간 지역성**: 특정 데이터 근처의 데이터도 접근될 가능성이 높다는 원리이다. 배열 인덱싱이 대표적인 예시로, `array[0]`에 접근하면 `array[1]`에도 접근할 가능성이 높다.Python
        
        # 
        
        `array = [10, 20, 30, 40]
        total = array[0] + array[1]
        print(total)`
        
- **시간 지역성** 덕분에 캐시는 한 번 사용한 데이터를 버리지 않고 보관함으로써 성능을 높이고, **공간 지역성** 덕분에 캐시는 데이터를 덩어리째로 가져와 미래의 요청을 미리 대비함으로써 성능을 높인다.

### 캐시 계층 구조

- **L1 캐시**: CPU 내부에 있으며 가장 빠르지만 용량이 가장 작다.
- **L2 캐시**: CPU 칩 안 또는 근처에 있으며 중간 속도와 용량을 가진다.
- **L3 캐시**: 멀티코어 CPU 전체가 공유하며, 용량은 크고 속도는 L1/L2보다 느리다.

### 저장장치 계층 구조 전체

      `▲  | 빠르고, 비싸고, 용량 작음
      │  └──────────> CPU 와의 접근성 높음
      │
┌───────────────┐
│ CPU 레지스터  │
├───────────────┤
│   L1/L2/L3 캐시   │
├───────────────┤
│   메인 메모리(RAM)   │
├───────────────┤
│ 보조 기억장치 │
└───────────────┘
      │
      │  ┌──────────> CPU 와의 접근성 낮음
      ▼  | 느리고, 저렴하고, 용량 큼`

### 분리형 캐시

코어와 가장 가까운 L1 캐시는 접근 속도를 높이기 위해 명령어만 저장하는 **L1I 캐시**와 데이터만 저장하는 **L1D 캐시**로 분리하는 경우도 있다.

### 동작 방식

CPU가 데이터를 요청했을 때, 캐시 메모리에 있으면(**Cache Hit**) 바로 전달한다. 없으면(**Cache Miss**) 메인 메모리에서 데이터를 가져와 캐시에 저장한 후 CPU에 전달한다. 캐시 적중률이 높으면 CPU의 메모리 접근 횟수를 줄일 수 있다.

- **캐시 적중률 =** 캐시 히트 횟수 / (캐시 히트 횟수 + 캐시 미스 횟수)
- **캐시 히트(Cache Hit)**: 자주 사용될 것으로 예측한 데이터가 실제로 캐시 메모리 내에 있어 CPU에서 바로 활용되는 경우이다.
- **캐시 미스(Cache Miss)**: 예측이 틀려 메인 메모리에서 필요한 데이터를 직접 가져와야 하는 경우이다.

### 장점 & 한계

- **장점**: 메모리 접근 지연을 크게 줄여 CPU 효율을 향상시킨다.
- **한계**: 용량이 작고, 캐시 미스가 발생하면 오히려 지연이 커질 수 있다.

---

### 심화 학습

### 캐시 매핑 (Cache Mapping): 데이터는 어디에?

캐시 매핑은 메인 메모리의 수많은 데이터 주소를 캐시의 한정된 공간에 연결(mapping)하는 방식에 대한 것이다.

- 직접 매핑 (Direct Mapping)
    
    "주소마다 자리가 정해져 있는 지정석 제도"
    
    메인 메모리의 여러 주소가 캐시의 단 하나의 위치를 공유하는 방식이다. 예를 들어, 메모리 0번, 10번, 20번 주소의 데이터는 무조건 캐시 0번 자리에만 들어갈 수 있다.
    
    - **장점**: 구현이 간단하고, 데이터를 찾을 때 해당 자리만 확인하면 되므로 빠르다.
    - **단점**: CPU가 메인 메모리 0번과 10번을 번갈아 계속 필요로 할 경우, 캐시 0번 자리에서 0번 데이터와 10번 데이터가 계속 서로를 쫓아내는 충돌(Conflict Miss)이 발생하여 캐시 효율이 떨어질 수 있다.
- 완전 연관 매핑 (Fully Associative Mapping)
    
    "아무 데나 들어가도 되는 자유석 제도"
    
    메인 메모리의 데이터가 캐시의 어떤 위치에든 자유롭게 저장될 수 있는 방식이다.
    
    - **장점**: 자리가 비어있기만 하면 충돌 없이 데이터를 저장할 수 있어 공간 효율성이 높다.
    - **단점**: 원하는 데이터가 캐시에 있는지 찾으려면 캐시의 모든 자리를 다 확인해야 한다. 이는 회로가 매우 복잡하고 비싸져서 현실적으로는 잘 쓰이지 않는다.
- 집합 연관 매핑 (Set-Associative Mapping)
    
    "지정 구역 내에서는 자유석!" (오늘날 CPU의 선택)
    
    위 두 방식의 장점을 합친 절충안이다. 캐시를 여러 개의 '집합(Set)'으로 나누고, 각 데이터는 정해진 집합 안에서는 아무 곳에나 자유롭게 들어갈 수 있다. 예를 들어, 메모리 0번, 10번 데이터는 캐시 A집합 안의 빈자리에, 메모리 1번, 11번 데이터는 캐시 B집합 안의 빈자리에 들어가는 방식이다. 직접 매핑의 충돌 문제를 크게 완화하면서도 완전 연관 매핑처럼 모든 곳을 탐색할 필요는 없어 가장 합리적인 방식으로, 현대의 CPU는 대부분 이 방식을 사용한다.
    

### 캐시 교체 정책 (Replacement Policy): 누구를 내보낼까?

캐시가 꽉 찼을 때 새로운 데이터를 넣으려면 기존 데이터 중 하나를 내보내야 한다. 이때 어떤 기준으로 퇴출할 데이터를 고르는지가 **교체 정책**이다.

'집합 연관 매핑'에서 한 집합의 자리가 꽉 찼는데 새로운 데이터가 그 집합으로 들어와야 하는 상황이 발생하면, 기존 데이터 중 하나를 교체해야 한다. 이 교체 기준이 바로 교체 정책이다.

가장 대표적인 정책은 **LRU(Least Recently Used)**이다.

- **LRU (Least Recently Used)**: 이름 그대로 "가장 오랫동안 사용되지 않은" 데이터를 교체하는 방식이다. 이는 "최근에 사용된 데이터는 곧 다시 사용될 것이다"라는 시간 지역성 원리에 가장 충실한 전략이다.
- 이 외에도 FIFO(First-In, First-Out), LFU(Least Frequently Used) 등이 있지만, 일반적으로 LRU가 가장 좋은 성능을 보여 많이 사용된다.

### 캐시 쓰기 정책 (Write Policy): 언제 기록할까?

CPU가 데이터를 수정하는 '쓰기(Write)' 연산을 할 때, 변경된 내용을 언제 메인 메모리에 반영할지를 결정하는 것이 **쓰기 정책**이다. CPU가 캐시에 있는 데이터를 'A=1'에서 'A=5'로 바꿨다고 가정한다. 이 변경 사항은 언젠가 메인 메모리에도 반영되어야 진짜로 저장된다.

- 즉시 쓰기 (Write-Through)
    
    "꼼꼼하게 바로바로!"
    
    데이터가 수정될 때마다 캐시와 메인 메모리에 동시에 변경 내용을 쓰는 방식이다.
    
    - **장점**: 캐시와 메인 메모리의 데이터가 항상 일치하여 데이터 정합성을 유지하기 쉽다.
    - **단점**: 쓰기 작업을 할 때마다 느린 메인 메모리에 접근해야 하므로 전체적인 속도가 느려진다.
- 나중 쓰기 (Write-Back)
    
    "일단 캐시에만 적어두고, 나중에 한꺼번에!"
    
    데이터가 수정되면 일단 캐시에만 기록하고, '이 데이터는 수정되었음(Dirty Bit)'이라고 표시만 해둔다. 그러다 이 데이터가 캐시에서 교체될 때, 그때 가서 변경된 내용을 메인 메모리에 한꺼번에 쓰는 방식이다.
    
    - **장점**: 쓰기 연산이 대부분 빠른 캐시에서만 이루어져서 속도가 매우 빠르다.
    - **단점**: 캐시와 메인 메모리의 데이터가 일시적으로 불일치하는 상태가 발생할 수 있고, 구현이 더 복잡하다.
- 일반적으로 성능이 중요하기 때문에 **Write-Back 방식**이 더 널리 사용된다.